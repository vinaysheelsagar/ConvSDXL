"""This module provides the naive_linechunk functionality for the ConvSDXL project.

It includes functions for processing and cleaning prompts before they are used
to generate images with different aesthetic styles. This preprocessing step is
crucial for ensuring that the inputs to the generation models are well-formed
and adhere to the expected format.

NOTE: 
- The package is still under development and may contain bugs 
- Docstrings were generated by an AI and require quality control checks to verify 
  their correctness and completeness.
"""

import os
import gc
from datetime import datetime
import torch
from PIL import Image
from diffusers import DiffusionPipeline, AutoencoderKL
from diffusers import StableDiffusionUpscalePipeline
from diffusers import StableDiffusionXLPipeline
from diffusers import StableDiffusionInpaintPipeline
from diffusers import StableDiffusionXLImg2ImgPipeline
from .enums import *


def _clean_prompt(prompt: str) -> str:
    """
    Clean the given prompt by stripping leading and trailing whitespace.
    
    Parameters:
    - prompt (str): The text prompt to clean.

    Returns:
    - str: The cleaned prompt with no leading or trailing whitespace.
    """
    cleaned_prompt = prompt.strip()
    return cleaned_prompt


def _clear_garbage():
    """
    Perform garbage collection to free up memory.
    
    This function calls the garbage collection mechanism of Python to 
    clean up memory by removing objects that are no longer in use.
    """
    gc.collect()


def _save_image(image, image_dir):
    """
    Save the provided image to the specified directory with a unique filename.

    Parameters:
    - image (Image): An instance of PIL.Image to be saved.
    - image_dir (str): The directory path where the image will be saved.

    The image is saved with the current datetime as its filename, ensuring uniqueness.
    The saved image format is PNG.
    """
    image_path = os.path.join(image_dir, f"{datetime.now()}.png")
    image.save(image_path, "PNG")


def add_design_to_prompt(
        design_type: DesignType,
        prompt: str | None = None,
        negative_prompt: str | None = None,
):
    """
        Add an aesthetic design type to the input prompt and negative prompt.

        This function takes an optional design type, prompt, and negative prompt.
        It then adds design-related keywords to the prompt to guide the image
        generation process towards a specific aesthetic style.

        Parameters:
        - design_type (DesignType):
            The type of aesthetic design to apply.

        - prompt (str|None):
            The original text prompt to enhance. Defaults to an empty string.

        - negative_prompt (str|None):
            Text for steering the generation away from undesired elements. 
            Defaults to an empty string.

        Returns:
        - tuple[str, str]: A tuple containing the enhanced prompt and negative prompt.
        """
    if not prompt:
        prompt = ""

    if not negative_prompt:
        negative_prompt = ""

    match design_type:
        case DesignType.DIGITAL_ART:
            designed_prompt = (
                f"concept art {prompt} . digital artwork, illustrative, painterly, "
                "matte painting, highly detailed")
            
            designed_negative_prompt = (
                f"{negative_prompt} photo, photorealistic, realism, ugly")

        case DesignType.ANIME:
            designed_prompt = (
                f"anime artwork {prompt} . anime style, key visual, vibrant, "
                "studio anime, highly detailed")
            
            designed_negative_prompt = (
                f"{negative_prompt} photo, deformed, black and white, realism, "
                "disfigured, low contrast")

        case DesignType.NEONPUNK:
            designed_prompt = (
                f"neonpunk style {prompt} . cyberpunk, vaporwave, neon, vibes, vibrant, "
                "stunningly beautiful, crisp, detailed, sleek, ultramodern, magenta "
                "highlights, dark purple shadows, high contrast, cinematic, ultra "
                "detailed, intricate, professional")
            
            designed_negative_prompt = (
                f"{negative_prompt} painting, drawing, illustration, glitch, deformed, "
                "mutated, cross-eyed, ugly, disfigured")

        case DesignType.PIXEL_ART:
            designed_prompt = (
                f"pixel-art {prompt} . low-res, blocky, pixel art style, 8-bit graphics")
            
            designed_negative_prompt = (
                f"{negative_prompt} sloppy, messy, blurry, noisy, highly detailed, ultra "
                "textured, photo, realistic")

        case DesignType.MINIMALIST:
            designed_prompt = (
                f"minimalist style {prompt} . simple, clean, uncluttered, modern, elegant")
            
            designed_negative_prompt = (
                f"{negative_prompt} ornate, complicated, highly detailed, cluttered, "
                "disordered, messy, noisy")

        case _:
            raise ValueError("No such DesignType")

    return designed_prompt, designed_negative_prompt


def preprocess_prompts(
    design_type: DesignType | None,
    prompt: str | None,
    negative_prompt: str | None,
    **model_kwargs,
):
    """
    Preprocess prompts and update model_kwargs with cleaned prompts and designed 
    prompts.

    Args:
        design_type (DesignType | None): 
            The type of design to apply to the prompts.
        
        prompt (str | None): 
            The prompt to be preprocessed.
        
        negative_prompt (str | None): 
            The negative prompt to be preprocessed.
        
        **model_kwargs: 
            Additional keyword arguments for the model.

    Returns:
        dict: The updated model_kwargs with cleaned and designed prompts.
    """
    if prompt:
        prompt = _clean_prompt(prompt)
        model_kwargs["prompt"] = prompt

    if negative_prompt:
        negative_prompt = _clean_prompt(negative_prompt)
        model_kwargs["negative_prompt"] = negative_prompt

    if design_type:
        designed_prompts = add_design_to_prompt(
            prompt=prompt,
            negative_prompt=negative_prompt,
            design_type=design_type,
        )

        model_kwargs["prompt"] = designed_prompts[0]
        model_kwargs["negative_prompt"] = designed_prompts[1]

    return model_kwargs


class ConvSDXL:
    """Handles the initialization and application of the Stable Diffusion XL models.

    This class provides methods to set up various Stable Diffusion XL pipelines 
    such as base generation, image-to-image, inpainting, and upscaling. It allows 
    users to leverage different AI models for content creation and modification 
    tasks.

    Attributes:
        _base (StableDiffusionXLPipeline | None): 
            The base generation pipeline.
        
        _refiner (StableDiffusionXLImg2ImgPipeline | None): 
            The image-to-image refinement pipeline.
        
        _inpaint (StableDiffusionXLPipeline | None): 
            The inpainting pipeline.
        
        _upscaler (StableDiffusionUpscalePipeline | None): 
            The upscaling pipeline.
    """
    _base: StableDiffusionXLPipeline | None = None
    _refiner: StableDiffusionXLImg2ImgPipeline | None = None
    _inpaint: StableDiffusionXLPipeline | None = None
    _upscaler: StableDiffusionUpscalePipeline | None = None

    def set_base(
        self,
        base_pipeline=None,
        model_name: str = "stabilityai/stable-diffusion-xl-base-1.0",
        torch_dtype: torch.dtype = torch.float16,
        variant: str = "fp16",
        use_safetensors: bool = True,
        **kwargs,
    ):
        """Sets up the base generation pipeline for the Stable Diffusion XL models.

        Args:
            base_pipeline (Optional[StableDiffusionXLPipeline]): 
                The pipeline instance to use as the base. If provided, this pipeline 
                will be set as the base without further configuration.
            
            model_name (str): 
                Name of the model to be loaded from the model hub. Defaults to the 
                specified model.
            
            torch_dtype (torch.dtype): 
                Data type to be used for model tensors. Defaults to torch.float16.
            
            variant (str): 
                The variant of the pipeline to be used. Defaults to "fp16".
            
            use_safetensors (bool): 
                Flag to indicate whether to use safe tensors. Defaults to True.
            
            **kwargs: 
                Additional keyword arguments to configure the pipeline.

        Returns:
            StableDiffusionXLPipeline | None: The configured base generation pipeline 
            or None if a pipeline instance was provided.
        """

        if base_pipeline:
            self._base = base_pipeline
            return self._base

        _clear_garbage()

        # vae = AutoencoderKL.from_pretrained(vae, torch_dtype=torch.float16)

        self._base = DiffusionPipeline.from_pretrained(
            pretrained_model_name_or_path = model_name,
            torch_dtype=torch_dtype,
            variant=variant,
            use_safetensors=use_safetensors,
            **kwargs
        )
        self._base.to("cuda")

        return self._base

    def remove_base(self):
        """
        Method to remove the base attribute and perform garbage collection.
        No parameters or return types specified.
        """
        self._base = None
        torch.cuda.empty_cache()
        _clear_garbage()

    def set_inpaint(
        self,
        inpaint_pipeline=None,
        model_name: str = "stabilityai/stable-diffusion-2-inpainting",
        torch_dtype: torch.dtype = torch.float16,
        variant: str = "fp16",
        use_safetensors: bool = True,
        **kwargs
    ):
        """
        Set the inpainting pipeline for the model.

        This method sets the inpainting pipeline for the model if it is provided,
        otherwise, it attempts to load the Stable Diffusion Inpaint Pipeline from
        the specified pretrained model name or path. Additional configurations
        for the pipeline can be provided through keyword arguments.

        Args:
            inpaint_pipeline (Optional[StableDiffusionInpaintPipeline]):
                The pipeline instance to use as the inpainting pipeline. If provided,
                this pipeline will be set as the inpainting pipeline without further
                configuration.
            
            model_name (str): 
                Name of the model to be loaded from the model hub. Defaults to the 
                specified model.
            
            torch_dtype (torch.dtype): 
                Data type to be used for model tensors. Defaults to torch.float16.
            
            variant (str): 
                The variant of the pipeline to be used. Defaults to "fp16".
            
            use_safetensors (bool): 
                Flag to indicate whether to use safe tensors. Defaults to True.
            
            **kwargs: 
                Additional keyword arguments to configure the pipeline.

        Returns (StableDiffusionInpaintPipeline):
            The configured inpainting pipeline.
        """

        if inpaint_pipeline:
            self._inpaint = inpaint_pipeline
            return self._inpaint

        _clear_garbage()

        self._inpaint = StableDiffusionInpaintPipeline.from_pretrained(
            pretrained_model_name_or_path = model_name,
            torch_dtype=torch_dtype,
            variant=variant,
            use_safetensors=use_safetensors,
            **kwargs,
        )
        self._inpaint.to("cuda")

        return self._inpaint

    def remove_inpaint(self):
        """
        Remove the inpaint attribute and clear the GPU memory and garbage.
        """
        self._inpaint = None
        torch.cuda.empty_cache()
        _clear_garbage()

    def set_refiner(
        self,
        refiner_pipeline=None,
        model_name: str = "stabilityai/stable-diffusion-xl-refiner-1.0",
        torch_dtype: torch.dtype = torch.float16,
        variant: str = "fp16",
        use_safetensors: bool = True,
        **kwargs
    ):
        """
        Set the refiner pipeline for the image generation process.

        This method allows setting a custom refiner pipeline or initializing
        a default stable diffusion XL refiner pipeline with provided parameters.
        If no custom refiner is provided, it will load the model specified by
        the 'model_name' parameter.

        Args:
            refiner_pipeline (DiffusionPipeline, optional): An instance of a
                pre-initialized refiner pipeline. If provided, this pipeline will
                be used as the refiner. Defaults to None.
            
            model_name (str): The name of the model to load from the Huggingface
                Hub. Defaults to "stabilityai/stable-diffusion-xl-refiner-1.0".
            
            torch_dtype (torch.dtype): The data type to be used by torch tensors.
                Defaults to torch.float16.
            
            variant (str): The variant of the model to be used. Defaults to "fp16".
            
            use_safetensors (bool): Whether to use safe tensors during the
                operation. Defaults to True.
            
            **kwargs: Additional keyword arguments that will be passed to the
                `from_pretrained` method when initializing the default refiner pipeline.

        Returns:
            DiffusionPipeline: The configured refiner pipeline.
        """

        if refiner_pipeline:
            self._refiner = refiner_pipeline
            return self._refiner

        _clear_garbage()

        # vae = AutoencoderKL.from_pretrained(vae, torch_dtype=torch.float16)

        self._refiner = DiffusionPipeline.from_pretrained(
            pretrained_model_name_or_path = model_name,
            torch_dtype=torch_dtype,
            variant=variant,
            use_safetensors=use_safetensors,
            **kwargs
        )
        self._refiner.to("cuda")

        return self._refiner

    def remove_refiner(self):
        """Method to remove the refiner and clear memory cache."""
        self._refiner = None
        torch.cuda.empty_cache()
        _clear_garbage()

    def set_upscaler(
        self,
        upscaler_pipeline=None,
        model_name: str = "stabilityai/stable-diffusion-x4-upscaler",
        torch_dtype: torch.dtype = torch.float16,
        variant: str = "fp16",
        use_safetensors: bool = True,
        enable_attention_slicing: bool = True,
        **kwargs
    ):
        """
        Sets up the upscaler model and its configurations.

        This method is responsible for initializing the upscaler component with a 
        specified model. If an upscaler object is provided, it will be used directly.
        Otherwise, the method will create a new upscaler using the `DiffusionPipeline.
        from_pretrained` method.

        Args:
            upscaler_pipeline (Optional[DiffusionPipeline]): 
                The existing upscaler pipeline to use. 
                If None, a new pipeline will be created.
            
            model_name (str): 
                The name of the model to load for upscaling.
            
            torch_dtype (torch.dtype): 
                The data type of the tensors to be used within the model.
            
            variant (str): 
                The variant of the model to be used.
            
            use_safetensors (bool): 
                Flag to indicate the use of safe tensors.
            
            enable_attention_slicing (bool): 
                Flag to enable attention slicing in the model.
            
            **kwargs: 
                Additional keyword arguments to pass to the `from_pretrained` method.

        Returns:
            DiffusionPipeline: The initialized upscaler model.
        """
        if upscaler_pipeline:
            self._upscaler = upscaler_pipeline
            return self._upscaler

        _clear_garbage()

        self._upscaler = DiffusionPipeline.from_pretrained(
            pretrained_model_name_or_path=model_name,
            torch_dtype=torch_dtype,
            variant=variant,
            use_safetensors=use_safetensors,
            **kwargs
        )
        self._upscaler.to("cuda")
        if enable_attention_slicing:
            self._upscaler.enable_attention_slicing()

        return self._upscaler

    def remove_upscaler(self):
        """Method to remove the upscaler and clear GPU memory."""
        self._upscaler = None
        torch.cuda.empty_cache()
        _clear_garbage()

    def get_image(
        self,
        prompt: str,
        negative_prompt: str = None,
        design_type: DesignType = None,
        image_dir: str | os.PathLike = None,
        **model_kwargs
    ):
        """Generates an image from a prompt using the base model.

        This method creates a directory if it does not exist, sets up the base model
        if it's not already set, processes the prompts, and then generates an image
        using the specified model arguments.

        Args:
            prompt (str): The main text prompt for image generation.
            negative_prompt (str, optional): Text for steering the model away from
                certain concepts.
            design_type (DesignType, optional): The desired design type for the image.
            image_dir (str | os.PathLike, optional): The directory where the generated
                image will be saved. It will be created if it does not exist.
            **model_kwargs: Additional keyword arguments to pass to the base model.

        Returns:
            Generated image object or path to the saved image file.
        """
        # Existing code continues here...
        os.makedirs(image_dir, exist_ok=True)

        if self._base is None:
            self.set_base()

        model_kwargs = preprocess_prompts(
            design_type=design_type,
            prompt=prompt,
            negative_prompt=negative_prompt,
        )

        image = self._base(
            **model_kwargs
        ).images[0]

        if image_dir is not None:
            _save_image(image, image_dir)

        return image

    def inpaint_image(
        self,
        prompt: str,
        image: Image,
        mask_image: Image,
        negative_prompt: str = None,
        design_type: DesignType = None,
        image_dir: str | os.PathLike = None,
        **model_kwargs,
    ):
        """Inpaints an image based on the given prompts and mask.

        This method applies inpainting to the provided image using the specified mask
        and prompts. It supports optional design types for customizing the style of 
        the inpainting result.

        Args:
            prompt (str): 
                The main prompt describing the desired changes.
            
            image (Image): 
                The original image to which inpainting will be applied.
            
            mask_image (Image): 
                The mask image where white pixels denote the area to inpaint.
            
            negative_prompt (str, optional): 
                An optional prompt describing undesired elements.
            
            design_type (DesignType, optional): 
                An optional enum value specifying the design type.
            
            image_dir (str | os.PathLike, optional): 
                Directory where the inpainted image will be saved.
            
            **model_kwargs: 
                Additional keyword arguments for the inpainting model.

        Returns:
            Image: The inpainted image.

        """
        os.makedirs(image_dir, exist_ok=True)

        if self._inpaint is None:
            self.set_inpaint()

        model_kwargs = preprocess_prompts(
            design_type=design_type,
            prompt=prompt,
            negative_prompt=negative_prompt,
        )

        image = self._inpaint(
            image=image,
            mask_image=mask_image,
            **model_kwargs
        ).images[0]

        if image_dir is not None:
            _save_image(image, image_dir)

        return image

    def refine_image(
        self,
        prompt: str,
        image: Image,
        negative_prompt: str = None,
        design_type: DesignType = None,
        image_dir: str | os.PathLike = None,
        **model_kwargs,
    ):
        """
        Refines the given image using the specified prompt and optional 
        design type, negative prompt, and image directory.

        Parameters:
            image (Image): 
                The input image to be refined.
            
            prompt (str): 
                The prompt to be used for refining the image.
            
            negative_prompt (str, optional): 
                The negative prompt to be used for refining the image. 
                Defaults to None.
            
            design_type (DesignType, optional): 
                The design type to be used for refining the image. 
                Defaults to None.
            
            image_dir (str | os.PathLike, optional): 
                The directory to save the refined image. 
                Defaults to None.
            
            **model_kwargs: 
                Additional keyword arguments to be passed to the refining model.

        Returns:
            The refined image.
        """

        os.makedirs(image_dir, exist_ok=True)

        if self._refiner is None:
            self.set_refiner()

        model_kwargs = preprocess_prompts(
            design_type=design_type,
            prompt=prompt,
            negative_prompt=negative_prompt,
        )

        image = self._refiner(
            image=image,
            **model_kwargs,
        ).images[0]

        if image_dir is not None:
            _save_image(image, image_dir)

        return image

    def upscale_image(
        self,
        prompt: str,
        image: Image,
        negative_prompt: str = None,
        design_type: DesignType = None,
        image_dir: str | os.PathLike = None,
        **model_kwargs,
    ):
        """Upscales a given image using the Stable Diffusion Upscale model.

        This method takes an image and uses the configured upscaler to enhance its resolution.
        It also allows for customization of the upscaling process using prompts and design types,
        affecting the upscaling aesthetic. The image can be saved to a specified directory.

        Args:
            image (Image): The image to be upscaled.
            prompt (str): A textual description used to guide the upscaling process.
            negative_prompt (str, optional): A textual description of undesired elements.
                Defaults to None.
            design_type (DesignType, optional): The design type to influence the upscaling style.
                Defaults to None.
            image_dir (str | os.PathLike, optional): The directory where the upscaled image will
                be saved. If None, the image won't be saved to disk. Defaults to None.

        Returns:
            Image: The upscaled image.

        Raises:
            Exception: If the upscaling model fails or an error occurs in the process.
        """
        # Function implementation remains unchanged
        os.makedirs(image_dir, exist_ok=True)

        if self._upscaler is None:
            self.set_upscaler()

        model_kwargs = preprocess_prompts(
            design_type=design_type,
            prompt=prompt,
            negative_prompt=negative_prompt,
        )

        image = self._upscaler(
            image=image,
            **model_kwargs,
        ).images[0]

        if image_dir is not None:
            _save_image(image, image_dir)

        return image
